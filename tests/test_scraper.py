#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã —Å–∫—Ä–∞–ø–µ—Ä–∞
"""

import asyncio
import logging
from src.core.universal_scraper import UniversalScraper

async def test_scraper():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∫—Ä–∞–ø–µ—Ä–∞"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    scraper = UniversalScraper()
    
    try:
        print("üîó –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Telegram...")
        await scraper.client.start()
        print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ!")
        
        print("üìã –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤...")
        channels = scraper.channel_manager.get_enabled_channels()
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(channels)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤:")
        for ch in channels:
            print(f"   - {ch.username} ({ch.parser_type})")
        
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä...")
        from src.parsers.simple_parser import SimpleParser
        parser = SimpleParser('job_parser')
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        class MockMessage:
            def __init__(self, text):
                self.text = text
        
        test_msg = MockMessage("Senior Python Developer at Google #python #ml @google")
        parsed = parser.parse_message(test_msg)
        print("‚úÖ –ü–∞—Ä—Å–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç:")
        print(f"   - –•–µ—à—Ç–µ–≥–∏: {parsed['hashtags']}")
        print(f"   - –£–ø–æ–º–∏–Ω–∞–Ω–∏—è: {parsed['mentions']}")
        print(f"   - –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: {parsed['technologies']}")
        
        print("üíæ –¢–µ—Å—Ç–∏—Ä—É–µ–º ClickHouse...")
        test_data = [{
            'message_id': 12345,
            'channel_username': '@test_channel',
            'date': '2024-09-16 20:00:00',
            'text': 'Test message',
            'views': 100,
            'forwards': 5,
            'hashtags': ['#test'],
            'mentions': ['@test'],
            'links': [],
            'technologies': ['python'],
            'companies': []
        }]
        
        scraper.clickhouse.insert_messages(test_data)
        print("‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ ClickHouse!")
        
        print("üéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    finally:
        await scraper.client.disconnect()

if __name__ == "__main__":
    asyncio.run(test_scraper())
